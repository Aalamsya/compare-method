A prediction (Latin præ-, "before," and dicere, "to say"), or forecast, is a statement about a future event[1]. A prediction is often, but not always, based upon experience or knowledge. There is no universal agreement about the exact difference between the two terms; different authors and disciplines ascribe different connotations. (Contrast with estimation.)

Although future events are necessarily uncertain, so guaranteed accurate information about the future is in many cases impossible, prediction can be useful to assist in making plans about possible developments; Howard H. Stevenson writes that prediction in business "... is at least two things: Important and hard."
In a non-statistical sense, the term "prediction" is often used to refer to an informed guess or opinion[3].

A prediction of this kind might be informed by a predicting person's abductive reasoning, inductive reasoning, deductive reasoning, and experience; and may be of useful — if the predicting person is a knowledgeable person in the field.[4]

The Delphi method is a technique for eliciting such expert-judgement-based predictions in a controlled way. This type of prediction might be perceived as consistent with statistical techniques in the sense that, at minimum, the "data" being used is the predicting expert's cognitive experiences forming an intuitive "probability curve."
In statistics, prediction is a part of statistical inference. One particular approach to such inference is known as predictive inference, but the prediction can be undertaken within any of the several approaches to statistical inference. Indeed, one possible description of statistics is that it provides a means of transferring knowledge about a sample of a population to the whole population, and to other related populations, which is not necessarily the same as prediction over time. When information is transferred across time, often to specific points in time, the process is known as forecasting.[5][not in citation given] Forecasting usually requires time series methods, while prediction is often performed on cross-sectional data.

Statistical techniques used for prediction include regression analysis and its various sub-categories such as linear regression, generalized linear models (logistic regression, Poisson regression, Probit regression), etc. In case of forecasting, autoregressive moving average models and vector autoregression models can be utilized. When these and/or related, generalized set of regression or machine learning methods are deployed in commercial usage, the field is known as predictive analytics.[6]

In many applications, such as time series analysis, it is possible to estimate the models that generate the observations. If models can be expressed as transfer functions or in terms of state-space parameters then smoothed, filtered and predicted data estimates can be calculated.[7] If the underlying generating models are linear then a minimum-variance Kalman filter and a minimum-variance smoother may be used to recover data of interest from noisy measurements. These techniques rely on one-step-ahead predictors (which minimise the variance of the prediction error). When the generating models are nonlinear then stepwise linearizations may be applied within Extended Kalman Filter and smoother recursions. However, in nonlinear cases, optimum minimum-variance performance guarantees no longer apply.[8]

To use regression analysis for prediction, data are collected on the variable that is to be predicted, called the dependent variable or response variable, and on one or more variables whose values are hypothesized to influence it, called independent variables or explanatory variables. A functional form, often linear, is hypothesized for the postulated causal relationship, and the parameters of the function are estimated from the data—that is, are chosen so as to optimize is some way the fit of the function, thus parameterized, to the data. That is the estimation step. For the prediction step, explanatory variable values that are deemed relevant to future (or current but not yet observed) values of the dependent variable are input to the parameterized function to generate predictions for the dependent variable.
In science, a prediction is a rigorous, often quantitative, statement, forecasting what would happen under specific conditions; for example, if an apple fell from a tree it would be attracted towards the center of the earth by gravity with a specified and constant acceleration. The scientific method is built on testing statements that are logical consequences of scientific theories. This is done through repeatable experiments or observational studies.

A scientific theory which is contradicted by observations and evidence will be rejected. New theories that generate many new predictions can more easily be supported or falsified (see predictive power). Notions that make no testable predictions are usually considered not to be part of science (protoscience or nescience) until testable predictions can be made.

Mathematical equations and models, and computer models, are frequently used to describe the past and future behaviour of a process within the boundaries of that model. In some cases the probability of an outcome, rather than a specific outcome, can be predicted, for example in much of quantum physics.

In microprocessors, branch prediction permits avoidance of pipeline emptying at branch instructions. In engineering, possible failure modes are predicted and avoided by correcting the mechanism causing the failure.

Accurate prediction and forecasting are very difficult in some areas, such as natural disasters, pandemics, demography, population dynamics and meteorology. For example, it is possible to predict the occurrence of solar cycles, but their exact timing and magnitude is much more difficult (see picture to right).
Established science makes useful predictions which are often extremely reliable and accurate; for example, eclipses are routinely predicted.

New theories make predictions which allow them to be disproved by reality. For example, predicting the structure of crystals at the atomic level is a current research challenge.[10] In the early 20th century the scientific consensus was that there existed an absolute frame of reference, which was given the name luminiferous ether. The existence of this absolute frame was deemed necessary for consistency with the established idea that the speed of light is constant. The famous Michelson-Morley experiment demonstrated that predictions deduced from this concept were not borne out in reality, thus disproving the theory of an absolute frame of reference. The special theory of relativity was proposed by Einstein as an explanation for the seeming inconsistency between the constancy of the speed of light and the non-existence of a special, preferred or absolute frame of reference.

Albert Einstein's theory of general relativity could not easily be tested as it did not produce any effects observable on a terrestrial scale. However, the theory predicted that large masses such as stars would bend light, in contradiction to accepted theory; this was observed in a 1919 eclipse.