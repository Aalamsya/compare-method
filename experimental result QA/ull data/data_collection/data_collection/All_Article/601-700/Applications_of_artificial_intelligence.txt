Artificial intelligence, defined as intelligence exhibited by machines, has many applications in today's society. More specifically, it is Weak AI, the form of A.I. where programs are developed to perform specific tasks, that is being utilized for a wide range of activities including medical diagnosis, electronic trading, robot control, and remote sensing. AI has been used to develop and advance numerous fields and industries, including finance, healthcare, education, transportation, and more.

AI for Good is a movement in which institutions are employing AI to tackle some of the world's greatest economic and social challenges. For example, the University of Southern California launched the Center for Artificial Intelligence in Society, with the goal of using AI to address socially relevant problems such as homelessness. At Stanford, researchers are using AI to analyze satellite images to identify which areas have the highest poverty levels.

The Air Operations Division (AOD) uses AI for the rule based expert systems. The AOD has use for artificial intelligence for surrogate operators for combat and training simulators, mission management aids, support systems for tactical decision making, and post processing of the simulator data into symbolic summaries. 

The use of artificial intelligence in simulators is proving to be very useful for the AOD. Airplane simulators are using artificial intelligence in order to process the data taken from simulated flights. Other than simulated flying, there is also simulated aircraft warfare. The computers are able to come up with the best success scenarios in these situations. The computers can also create strategies based on the placement, size, speed and strength of the forces and counter forces. Pilots may be given assistance in the air during combat by computers. The artificial intelligent programs can sort the information and provide the pilot with the best possible maneuvers, not to mention getting rid of certain maneuvers that would be impossible for a human being to perform. Multiple aircraft are needed to get good approximations for some calculations so computer simulated pilots are used to gather data. These computer simulated pilots are also used to train future air traffic controllers.

The system used by the AOD in order to measure performance was the Interactive Fault Diagnosis and Isolation System, or IFDIS. It is a rule based expert system put together by collecting information from TF-30 documents and the expert advice from mechanics that work on the TF-30. This system was designed to be used for the development of the TF-30 for the RAAF F-111C. The performance system was also used to replace specialized workers. The system allowed the regular workers to communicate with the system and avoid mistakes, miscalculations, or having to speak to one of the specialized workers.

The AOD also uses artificial intelligence in speech recognition software. The air traffic controllers are giving directions to the artificial pilots and the AOD wants to the pilots to respond to the ATC's with simple responses. The programs that incorporate the speech software must be trained, which means they use neural networks. The program used, the Verbex 7000, is still a very early program that has plenty of room for improvement. The improvements are imperative because ATCs use very specific dialog and the software needs to be able to communicate correctly and promptly every time.

The Artificial Intelligence supported Design of Aircraft, or AIDA, is used to help designers in the process of creating conceptual designs of aircraft. This program allows the designers to focus more on the design itself and less on the design process. The software also allows the user to focus less on the software tools. The AIDA uses rule based systems to compute its data. This is a diagram of the arrangement of the AIDA modules. Although simple, the program is proving effective.

In 2003, NASA's Dryden Flight Research Center, and many other companies, created software that could enable a damaged aircraft to continue flight until a safe landing zone can be reached. The software compensates for all the damaged components by relying on the undamaged components. The neural network used in the software proved to be effective and marked a triumph for artificial intelligence.

The Integrated Vehicle Health Management system, also used by NASA, on board an aircraft must process and interpret data taken from the various sensors on the aircraft. The system needs to be able to determine the structural integrity of the aircraft. The system also needs to implement protocols in case of any damage taken the vehicle. 

Haitham Baomar and Peter Bentley are leading a team from the University College of London to develop an artificial intelligence based Intelligent Autopilot System (IAS) designed to teach an autopilot system to behave like a highly experienced pilot who is faced with an emergency situation such as severe weather, turbulence, or system failure. Educating the autopilot relies on the concept of supervised machine learning “which treats the young autopilot as a human apprentice going to a flying school”. The autopilot records the actions of the human pilot generating learning models using artificial neural networks. The autopilot is then given full control and observed by the pilot as it executes the training exercise. 

The Intelligent Autopilot System combines the principles of Apprenticeship Learning and Behavioral Cloning whereby the autopilot observes the low-level actions required to maneuver the airplane and high-level strategy used to apply those actions. IAS implementation employs three phases; pilot data collection, training, and autonomous control. Baomar and Bentley’s goal is to create a more autonomous autopilot to assist pilots in responding to emergency situations.

AI researchers have created many tools to solve the most difficult problems in computer science. Many of their inventions have been adopted by mainstream computer science and are no longer considered a part of AI. (See AI effect.) According to Russell & Norvig (2003, p. 15), all of the following were originally developed in AI laboratories: time sharing, interactive interpreters, graphical user interfaces and the computer mouse, rapid development environments, the linked list data structure, automatic storage management, symbolic programming, functional programming, dynamic programming and object-oriented programming.

AI can be used to potentially determine the developer of anonymous binaries.

AI can be used to create other AI. For example, around November 2017, Google's AutoML project to evolve new neural net topologies created NASNet, a system optimized for ImageNet and COCO. According to Google, NASNet's performance exceeded all previously published ImageNet performance.

There are a number of companies that create robots to teach subjects to children ranging from biology to computer science, though such tools have not become widespread yet. There have also been a rise of intelligent tutoring systems, or ITS, in higher education. For example, an ITS called SHERLOCK teaches Air Force technicians to diagnose electrical systems problems in aircraft. Another example is DARPA, Defense Advanced Research Projects Agency, which used AI to develop a digital tutor to train its Navy recruits in technical skills in a shorter amount of time. Universities have been slow in adopting AI technologies due to either a lack of funding or skepticism of the effectiveness of these tools, but in the coming years more classrooms will be utilizing technologies such as ITS to complement teachers.

Advancements in natural language processing, combined with machine learning, have also enabled automatic grading of assignments as well as a data-driven understanding of individual students’ learning needs. This led to an explosion in popularity of MOOCs, or Massive Open Online Courses, which allows students from around the world to take classes online. Data sets collected from these large scale online learning systems have also enabled learning analytics, which will be used to improve the quality of learning at scale. Examples of how learning analytics can be used to improve the quality of learning include predicting which students are at risk of failure and analyzing student engagement.

Algorithmic trading involves the use of complex AI systems to make trading decisions at speeds several orders of magnitudes greater than any human is capable of, often making millions of trades in a day without any human intervention. Automated trading systems are typically used by large institutional investors.

Several large financial institutions have invested in AI engines to assist with their investment practices. BlackRock’s AI engine, Aladdin, is used both within the company and to clients to help with investment decisions. Its wide range of functionalities includes the use of natural language processing to read text such as news, broker reports, and social media feeds. It then gauges the sentiment on the companies mentioned and assigns a score. Banks such as UBS and Deutsche Bank use an AI engine called Sqreem (Sequential Quantum Reduction and Extraction Model) which can mine data to develop consumer profiles and match them with the wealth management products they’d most likely want. Goldman Sachs uses Kensho, a market analytics platform that combines statistical computing with big data and natural language processing. Its machine learning systems mine through hoards of data on the web and assess correlations between world events and their impact on asset prices. Information Extraction, part of artificial intelligence, is used to extract information from live news feed and to assist with investment decisions.

Several products are emerging that utilize AI to assist people with their personal finances. For example, Digit is an app powered by artificial intelligence that automatically helps consumers optimize their spending and savings based on their own personal habits and goals. The app can analyze factors such as monthly income, current balance, and spending habits, then make its own decisions and transfer money to the savings account. Wallet.AI, an upcoming startup in San Francisco, builds agents that analyze data that a consumer would leave behind, from Smartphone check-ins to tweets, to inform the consumer about their spending behavior.

Robo-advisors are becoming more widely used in the investment management industry. Robo-advisors provide financial advice and portfolio management with minimal human intervention. This class of financial advisers work based on algorithms built to automatically develop a financial portfolio according to the investment goals and risk tolerance of the clients. It can adjust to real-time changes in the market and accordingly calibrate the portfolio.

An online lender, Upstart, analyze vast amounts of consumer data and utilizes machine learning algorithms to develop credit risk models that predict a consumer’s likelihood of default. Their technology will be licensed to banks for them to leverage for their underwriting processes as well. 

ZestFinance developed their Zest Automated Machine Learning (ZAML) Platform specifically for credit underwriting as well. This platform utilizes machine learning to analyze tens of thousands traditional and nontraditional variables (from purchase transactions to how a customer fills out a form) used in the credit industry to score borrowers. The platform is particularly useful to assign credit scores to those with limited credit histories, such as millennials.

The job market has seen a notable change due to Artificial intelligence implementation. It has simplified the process for both recruiters and job seekers (i.e., Google for Jobs and applying online). According to Raj Mukherjee from Indeed.com, 65% of people launch a job search again within 91 days of being hired. AI-powered engine streamlines the complexity of job hunting by operating information on job skills, salaries, and user tendencies, matching people to the most relevant positions. Machine intelligence calculates what wages would be appropriate for a particular job, pulls and highlights resume information for recruiters using natural language processing, which extracts relevant words and phrases from text using specialized software. Another application is an AI resume builder which requires 5 minutes to compile a CV as opposed to spending hours doing the same job. In the AI age chatbots assist website visitors and solve daily workflows. Revolutionary AI tools complement people’s skills and allow HR managers to focus on tasks of higher priority. However, Artificial Intelligence impact on jobs research suggests that by 2030 intelligent agents and robots can eliminate 30% of the world’s human labor. Moreover, the research proves automation will displace between 400 and 800 million employees. Glassdoor`s research report states that recruiting and HR are expected to see much broader adoption of AI in job market 2018 and beyond.

Robots have become common in many industries and are often given jobs that are considered dangerous to humans. Robots have proven effective in jobs that are very repetitive which may lead to mistakes or accidents due to a lapse in concentration and other jobs which humans may find degrading.

In 2014, China, Japan, the United States, the Republic of Korea and Germany together amounted to 70% of the total sales volume of robots. In the automotive industry, a sector with particularly high degree of automation, Japan had the highest density of industrial robots in the world: 1,414 per 10,000 employees.

Another application of AI is in the human resources and recruiting space. There are three ways AI is being used by human resources and recruiting professionals. AI is used to screen resumes and rank candidates according to their level of qualification. Ai is also used to predict candidate success in given roles through job matching platforms. And now, AI is rolling out recruiting chat bots that can automate repetitive communication tasks.

Typically, resume screening involves a recruiter or other HR professional scanning through a database of resumes. Now startups like Pomato, are creating machine learning algorithms to automate resume screening processes. Pomato’s resume screening AI focuses on automating validating technical applicants for technical staffing firms. Pomato’ s AI performs over 200,000 computations on each resume in seconds then designs a custom technical interview based on the mined skills. KE Solutions, founded in 2014, has developed recommendation systems to rank jobs for candidates, and rank resumes for employers. jobster.io, developed by KE Solutions uses concept-based search has increased accuracy by 80% compared to traditional ATS. It helps recruiters to overcome technical barriers.

From 2016 to 2017, consumer goods company Unilever used artificial intelligence to screen all entry level employees. Unilever’s AI used neuroscience based games, recorded interviews, and facial/speech analysis to predict hiring success. Unilever partnered with Pymetrics and HireVue to enable its novel AI based screening and increased their applicants from 15,000 to 30,000 in a single year. Recruiting with AI also produced Unililever’s “most diverse class to date.’ Unilever also decreased time to hire from 4 months to 4 weeks and saved over 50,000 hours of recruiter time.

From resume screening to neuroscience, speech recognition, and facial analysis...it’s clear AI is having a massive impact on the human resources field. Yet another development in AI is in recruiting chatbots. TextRecruit, a Bay Area startup, released Ari (automated recruiting interface.) Ari is a recruiting chatbot that is designed to hold two-way text message conversations with candidates. Ari automates posting jobs, advertising openings, screening candidates, scheduling interviews, and nurturing candidate relationships with updates as they progress along the hiring funnel. Ari is currently offered as part of TextRecruit’s candidate engagement platform.

Some AI applications are geared towards the analysis of audiovisual media content such as movies, TV programs, advertisement videos or user-generated content. The solutions often involve computer vision, which is a major application area of AI.

Typical use case scenarios include the analysis of images using object recognition or face recognition techniques, or the analysis of video for recognizing relevant scenes, objects or faces. The motivation for using AI-based media analysis can be — among other things — the facilitation of media search, the creation of a set of descriptive keywords for a media item, media content policy monitoring (such as verifying the suitability of content for a particular TV viewing time), speech to text for archival or other purposes, and the detection of logos, products or celebrity faces for the placement of relevant advertisements.

Media analysis AI companies often provide their services over a REST API that enables machine-based automatic access to the technology and allows machine-reading of the results. For example, IBM, Microsoft, Amazon and the video AI company Valossa allow access to their media recognition technology by using RESTful APIs.

Among notable early efforts, David Cope created an AI called Emily Howell that managed to become well known in the field of Algorithmic Computer Music. The algorithm behind Emily Howell is registered as a US patent. 

The AI Iamus created 2012 the first complete classical album fully composed by a computer.

Other endeavours, like AIVA (Artificial Intelligence Virtual Artist), focus on composing symphonic music, mainly classical music for film scores. It achieved a world first by becoming the first virtual composer to be recognized by a musical professional association. 

Artificial intelligences can even produce music usable in a medical setting, with Melomics’s effort to use computer-generated music for stress and pain relief.

Moreover, initiatives such as Google Magenta, conducted by the Google Brain team, want to find out if an artificial intelligence can be capable of creating compelling art. 

At Sony CSL Research Laboratory, their Flow Machines software has created pop songs by learning music styles from a huge database of songs. By analyzing unique combinations of styles and optimizing techniques, it can compose in any style.

Another artificial intelligence musical composition project, The Watson Beat, written by IBM Research, doesn't need a huge database of music like the Google Magenta and Flow Machines projects, since it uses Reinforcement Learning and Deep Belief Networks to compose music on a simple seed input melody and a select style. Since the software has been open sourced musicians, such as Taryn Southern have been collaborating with the project to create music.

The company Narrative Science makes computer generated news and reports commercially available, including summarizing team sporting events based on statistical data from the game in English. It also creates financial reports and real estate analyses. Similarly, the company Automated Insights generates personalized recaps and previews for Yahoo Sports Fantasy Football. The company is projected to generate one billion stories in 2014, up from 350 million in 2013. 

Echobox is a software company that helps publishers increase traffic by 'intelligently' posting articles on social media platforms such as Facebook and Twitter. By analysing large amounts of data, it learns how specific audiences respond to different articles at different times of the day. It then chooses the best stories to post and the best times to post them. It uses both historical and real-time data to understand to what has worked well in the past as well as what is currently trending on the web.

Another company, called Yseop, uses artificial intelligence to turn structured data into intelligent comments and recommendations in natural language. Yseop is able to write financial reports, executive summaries, personalized sales or marketing documents and more at a speed of thousands of pages per second and in multiple languages including English, Spanish, French & German. 

Boomtrain’s is another example of AI that is designed to learn how to best engage each individual reader with the exact articles — sent through the right channel at the right time — that will be most relevant to the reader. It’s like hiring a personal editor for each individual reader to curate the perfect reading experience.

There is also the possibility that AI will write work in the future. In 2016, a Japanese AI co-wrote a short story and almost won a literary prize.

Artificial intelligence is implemented in automated online assistants that can be seen as avatars on web pages. It can avail for enterprises to reduce their operation and training cost. A major underlying technology to such systems is natural language processing. Pypestream uses automated customer service for its mobile application designed to streamline communication with customers. 

Currently, major companies are investing in AI to handle difficult customer in the future. Google's most recent development analyzes language and converts speech into text. The platform can identify angry customers through their language and respond appropriately.

Artificial Intelligence has been combined with many sensor technologies, such as Digital SpectrometryTM by IdeaCuria Inc. which enables many applications such as at home water quality monitoring.

Many telecommunications companies make use of heuristic search in the management of their workforces, for example BT Group has deployed heuristic search in a scheduling application that provides the work schedules of 20,000 engineers.

The 1990s saw some of the first attempts to mass-produce domestically aimed types of basic Artificial Intelligence for education, or leisure. This prospered greatly with the Digital Revolution, and helped introduce people, especially children, to a life of dealing with various types of Artificial Intelligence, specifically in the form of Tamagotchis and Giga Pets, iPod Touch, the Internet, and the first widely released robot, Furby. A mere year later an improved type of domestic robot was released in the form of Aibo, a robotic dog with intelligent features and autonomy.

Companies like Mattel have been creating an assortment of AI-enabled toys for kids as young as age three. Using proprietary AI engines and speech recognition tools, they are able to understand conversations, give intelligent responses and learn quickly. 

AI has also been applied to video games, for example video game bots, which are designed to stand in as opponents where humans aren't available or desired.

Fuzzy logic controllers have been developed for automatic gearboxes in automobiles. For example, the 2006 Audi TT, VW Touareg and VW Caravell feature the DSP transmission which utilizes Fuzzy Logic. A number of Škoda variants (Škoda Fabia) also currently include a Fuzzy Logic-based controller.

Today's cars now have AI-based driver assist features such as self-parking and advanced cruise controls. AI has been used to optimize traffic management applications, which in turn reduces wait times, energy use, and emissions by as much as 25 percent. In the future, fully autonomous cars will be developed. AI in transportation is expected to provide safe, efficient, and reliable transportation while minimizing the impact on the environment and communities. The major challenge to developing this AI is the fact that transportation systems are inherently complex systems involving a very large number of components and different parties, each having different and often conflicting objectives.

Various tools of artificial intelligence are also being widely deployed in homeland security, speech and text recognition, data mining, and e-mail spam filtering. Applications are also being developed for gesture recognition (understanding of sign language by machines), individual voice recognition, global voice recognition (from a variety of people in a noisy room), facial expression recognition for interpretation of emotion and non verbal cues. Other applications are robot navigation, obstacle avoidance, and object recognition.