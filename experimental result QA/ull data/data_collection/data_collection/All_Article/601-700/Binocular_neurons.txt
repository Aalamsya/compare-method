Binocular neurons are neurons in the visual system that assist in the creation of stereopsis from binocular disparity. They have been found in the primary visual cortex where the initial stage of binocular convergence begins.[1][2] Binocular neurons receive inputs from both the right and left eyes and integrate the signals together to create a perception of depth.
In the 19th century Charles Wheatstone determined that retinal disparity was a large contributor to depth perception.[1] Using a stereoscope, he showed that horizontal disparity is used by the brain to calculate the relative depths of different objects in 3-dimensional space in reference to a fixed point. This process is called stereopsis. Two main classes of cells in visual cortex were identified by David H. Hubel and Torsten Wiesel in 1962 through their investigation of the cat's primary visual cortex.[3] These classes were called simple and complex cells, which differ in how their receptive fields respond to light and dark stimuli. BÃ©la Julesz in 1971 used random dot stereograms to find that monocular depth cues, such as shading, are not required for stereoscopic vision.[1] Disparity selective cells were first recorded in the striate cortex (V1) of the cat by Peter Orlebar Bishop and John Douglas Pettigrew in the late 1960s,[1] however this discovery was unexpected and was not published until 1986.[4] These disparity selective cells, also known as binocular neurons, were again found in the awake behaving macaque monkey in 1985.[5] Additionally, population responses of binocular neurons have been found in human ventral and dorsal pathways using fMRI.
Both the dorsal and ventral pathways contribute to the perception of depth.[7] Binocular neurons, in the sense of being activated by stimuli in either eye, are first found in the visual cortex in layer 4.[7][8] Binocular neurons appear in the striate cortex (V1), the prestriate cortex (V2), the ventral extrastriate area (V4), the dorsal extrastriate area (V5/MT), medial superior temporal area, caudal intraparietal area, and a collection of areas in the anterior inferior temporal cortex.[7] Neurons in the prestriate cortex (V2) are more sensitive to different disparities than those in the striate cortex (V1).[7] Binocular neurons in the striate cortex (V1) are only sensitive to absolute disparity, where in other visual cortical areas they are sensitive to relative disparity.[7][9]

In the prestriate cortex (V2) and ventral extrastriate area (V4), binocular neurons respond most readily to a centre-surround stimulus.[7] A centre-surround stimulus consists of a fixed object with another object rotating in a circle around the fixed object. Areas in the anterior inferior temporal cortex respond to surface curvature.[7] Binocular neurons in both the caudal intraparietal area and the dorsal extrastriate area (V5/MT) respond to surface slants.[7] Binocular neurons in both the medial superior temporal area and dorsal extrastriate area (V5/MT) respond to surface depth sparation.[clarification needed][7] On one hand, the anticorrelated response of the binocular neurons in the striate cortex (V1), the prestriate cortex (V2), dorsal extrastriate area (V5/MT), and medial superior temporal area, all show similar responses.[7] On the other hand, binocular neurons in the ventral extrastriate area (V4) show weaker anticorrelated responses in comparison to the other areas. Finally, areas in the anterior inferior temporal cortex do not show any anticorrelated response.
Binocular neurons create depth perception through computation of relative and absolute disparity created by differences in the distance between the left and right eyes. Binocular neurons in the dorsal and ventral pathways combine to create depth perception, however, the two pathways perform differ in the type of stereo computation they perform.[7] The dorsal pathway generally performs a cross-correlation based upon the region of the different retinal images, while the ventral pathway fixes the multiple matching problem. In combination, the two pathways allow for judgments about stereo depth.[7] In general the ventral pathway is more sensitive to relative disparity. The cells in this pathway are sensitive to the relative depth between different objects or features close to one another in the physical world which is called fine stereopsis. The dorsal pathway contains cells that are more sensitive to coarse stereopsis. This allows for simple computations of depth based upon the different images in both the left and right eyes, but this computation only occurs when the surfaces analyzed contain a gradient of different depths.
Simple cells have separate regions in their receptive field that respond to light and dark stimuli. Unlike simple cells, the receptive field of complex cells have a mix of regions that respond to light and dark stimuli. The prevailing theory of how simple and complex cells interact is that cells in the lateral geniculate nucleus stimulate simple cells, and simple cells in turn stimulate complex cells where then a combination of complex cells create depth perception.[1][7][10] Three different cell types exist: far cells, near cells, and tuned zero cells. Far cells respond to disparities in planes further away from the plane of fixation, near cells are stimulated by disparities in planes closer than the plane of fixation, and tuned zero cells respond to disparities on the plane of fixation.[8][11] The plane of fixation is the plane in 3-dimensional space on which the two eyes are focused and is parallel to the coronal plane of the head.
The correspondence problem questions how the visual system determines what features or objects contained within the two retinal images come from the same real world objects.[1] For example, when looking at a picture of a tree, the visual system must determine that the two retinal images of the tree come from the same actual object in space. If the correspondence problem is not overcome in this case, the organism would perceive two trees when there is only one. In order to solve this problem, the visual system must have a way of avoiding false-matches of the two retinal images.[12] A possible way the visual system avoids false-matches is that binocular complex cells have cross-matching patches between their receptive fields, meaning that multiple complex cells would be stimulated by same feature.[1][13] Simulation of real binocular complex cells involves a hierarchical squared summation of multiple simple cell receptive fields where the simple cells sum the contribution from both the right and left retinal images.
An energy model, a kind of stimulus-response model, of binocular neurons allows for investigation behind the computational function these disparity tuned cells play in the creation of depth perception.[1][13][14][15] Energy models of binocular neurons involve the combination of monocular receptive fields that are either shifted in position or phase.[1][13] These shifts in either position or phase allow for the simulated binocular neurons to be sensitive to disparity. The relative contributions of phase and position shifts in simple and complex cells combine together in order to create depth perception of an object in 3-dimensional space.[13][14] Binocular simple cells are modeled as linear neurons. Due to the linear nature of these neurons, positive and negative values are encoded by two neurons where one neuron encodes the positive part and the other the negative part. This results in the neurons being complements of each other where the excitatory region of one binocular simple cell overlaps with the inhibitory region of another.[13][14] Each neuron's response is limited such that only one may have a non-zero response for any time. This kind of limitation is called halfwave-rectifing. Binocular complex cells are modeled as energy neurons since they do not have discrete on and off regions in their receptive fields.Energy neurons sum the squared responses of two pairs of linear neurons which must be 90 degrees out of phase.[13] Alternatively, they can also be the sum the squared responses of four halfwave-rectified linear neurons.