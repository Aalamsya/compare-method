The Loebner Prize is an annual competition in artificial intelligence that awards prizes to the computer programs considered by the judges to be the most human-like. The format of the competition is that of a standard Turing test. In each round, a human judge simultaneously holds textual conversations with a computer program and a human being via computer. Based upon the responses, the judge must decide which is which.

The contest was launched in 1990 by Hugh Loebner in conjunction with the Cambridge Center for Behavioral Studies, Massachusetts, United States. Since 2014[1] it has been organised by the AISB at Bletchley Park.[2] It has also been associated with Flinders University, Dartmouth College, the Science Museum in London, University of Reading and Ulster University, Magee Campus, Derry, UK City of Culture. In 2004 and 2005, it was held in Loebner's apartment in New York City. Within the field of artificial intelligence, the Loebner Prize is somewhat controversial; the most prominent critic, Marvin Minsky, called it a publicity stunt that does not help the field along.
Prizes[edit]
Originally, $2,000 was awarded for the most human-seeming program in the competition. The prize was $3,000 in 2005 and $2,250 in 2006. In 2008, $3,000 was awarded.

In addition, there are two one-time-only prizes that have never been awarded. $25,000 is offered for the first program that judges cannot distinguish from a real human and which can convince judges that the human is the computer program. $100,000 is the reward for the first program that judges cannot distinguish from a real human in a Turing test that includes deciphering and understanding text, visual, and auditory input. Once this is achieved, the annual competition will end.

Competition rules and restrictions[edit]
The rules have varied over the years and early competitions featured restricted conversation Turing tests[4] but since 1995 the discussion has been unrestricted.[5]

For the three entries in 2007, Robert Medeksza, Noah Duncan and Rollo Carpenter,[6] some basic "screening questions" were used by the sponsor to evaluate the state of the technology. These included simple questions about the time, what round of the contest it is, etc.; general knowledge ("What is a hammer for?"); comparisons ("Which is faster, a train or a plane?"); and questions demonstrating memory for preceding parts of the same conversation. "All nouns, adjectives and verbs will come from a dictionary suitable for children or adolescents under the age of 12." Entries did not need to respond "intelligently" to the questions to be accepted.

For the first time in 2008 the sponsor allowed introduction of a preliminary phase to the contest opening up the competition to previously disallowed web-based entries judged by a variety of invited interrogators. The available rules do not state how interrogators are selected or instructed. Interrogators (who judge the systems) have limited time: 5 minutes per entity in the 2003 competition, 20+ per pair in 2004â€“2007 competitions, 5 minutes to conduct simultaneous conversations with a human and the program in 2008-2009, increased to 25 minutes of simultaneous conversation since 2010.

Criticisms[edit]
The prize has long been scorned by experts in the field,[7] for a variety of reasons.

It is regarded by many as a publicity stunt.[8][9] Marvin Minsky scathingly offered a "prize" to anyone who could stop the competition. Loebner responded by jokingly observing that Minsky's offering a prize to stop the competition effectively made him a co-sponsor.[10]

The rules of the competition have encouraged poorly qualified judges to make rapid judgements. Interactions between judges and competitors was originally very brief, for example effectively 2.5 mins of questioning, which permitted only a few questions.[8] Questioning was initially restricted to "whimsical conversation",[7] a domain suiting standard chatbot tricks.[11]

Competition entrants do not aim at understanding or intelligence but resort to basic ELIZA style tricks,[8][12] and successful entrants find deception and pretense is rewarded.[13]

Reporting of the annual competition often confuses the imitation test with intelligence,[14] a typical example being Brian Christian's introduction to his article "Mind vs. Machine" in The Atlantic, March 2011,[15] stating that "in the race to build computers that can think like humans, the proving ground is the Turing Test".