Neuromorphic engineering, also known as neuromorphic computing,[1][2][3] is a concept developed by Carver Mead,[4] in the late 1980s, describing the use of very-large-scale integration (VLSI) systems containing electronic analog circuits to mimic neuro-biological architectures present in the nervous system.[5] In recent times the term neuromorphic has been used to describe analog, digital, mixed-mode analog/digital VLSI, and software systems that implement models of neural systems (for perception, motor control, or multisensory integration). The implementation of neuromorphic computing on the hardware level can be realized by oxide-based memristors,[6] threshold switches, and transistors.[7]

A key aspect of neuromorphic engineering is understanding how the morphology of individual neurons, circuits, applications, and overall architectures creates desirable computations, affects how information is represented, influences robustness to damage, incorporates learning and development, adapts to local change (plasticity), and facilitates evolutionary change.

Neuromorphic engineering is an interdisciplinary subject that takes inspiration from biology, physics, mathematics, computer science, and electronic engineering to design artificial neural systems, such as vision systems, head-eye systems, auditory processors, and autonomous robots, whose physical architecture and design principles are based on those of biological nervous systems.[8] 

As early as 2006, researchers at Georgia Tech published a field programmable neural array.[9] This chip was the first in a line of increasingly complex arrays of floating gate transistors that allowed programmability of charge on the gates of MOSFETs to model the channel-ion characteristics of neurons in the brain and was one of the first cases of a silicon programmable array of neurons.

In November 2011, a group of MIT researchers created a computer chip that mimics the analog, ion-based communication in a synapse between two neurons using 400 transistors and standard CMOS manufacturing techniques.[10][11]

In June 2012, spintronic researchers at Purdue presented a paper on the design of a neuromorphic chip using lateral spin valves and memristors. They argue that the architecture works similarly to neurons and can therefore be used to test methods of reproducing the brain's processing. In addition, these chips are significantly more energy-efficient than conventional ones.[12]

Research at HP Labs on Mott memristors has shown that while they can be non-volatile, the volatile behavior exhibited at temperatures significantly below the phase transition temperature can be exploited to fabricate a neuristor,[13] a biologically-inspired device that mimics behavior found in neurons.[13] In September 2013 they presented models and simulations that show how the spiking behavior of these neuristors can be used to form the components required for a Turing machine.[14]

Neurogrid, built by Brains in Silicon at Stanford University,[15] is an example of hardware designed using neuromorphic engineering principles. The circuit board is composed of 16 custom-designed chips, referred to as NeuroCores. Each NeuroCore's analog circuitry is designed to emulate neural elements for 65536 neurons, maximizing energy efficiency. The emulated neurons are connected using digital circuitry designed to maximize spiking throughput.[16][17]

A research project with implications for neuromorphic engineering is the Human Brain Project, a 10-year collaboration that is attempting to simulate a complete human brain in a supercomputer using biological data. It is made up of a group of researchers in neuroscience, medicine, and computing.[18] Henry Markram, the project's co-director, has stated that the project proposes to establish a foundation to explore and understand the brain and its diseases, and to use that knowledge to build new computing technologies. The three primary goals of the project are to better understand how the pieces of the brain fit and work together, to understand how to objectively diagnose and treat brain diseases, and to use the understanding of the human brain to develop neuromorphic computers. That the simulation of a complete human brain will require a supercomputer a thousand times more powerful than today's encourages the current focus on neuromorphic computers.[19] $1.3 billion has been allocated to the project by The European Commission.[20]

Other research with implications for neuromorphic engineering involves the BRAIN Initiative[21] and the TrueNorth chip from IBM.[22] Neuromorphic devices have also been demonstrated using nanocrystals, nanowires, and conducting polymers.[23]

Intel unveiled its neuromorphic research chip, called "Loihi", in October 2017. The chip uses an asynchronous spiking neural network (SNN) to implement adaptive self-modifying event-driven fine-grained parallel computations used to implement learning and inference with high efficiency.

Neuromemristive systems are a subclass of neuromorphic computing systems that focus on the use of memristors to implement neuroplasticity. While neuromorphic engineering focuses on mimicking biological behavior, neuromemristive systems focus on abstraction.[26] For example, a neuromemristive system may replace the details of a cortical microcircuit's behavior with an abstract neural network model.[27]

There exist several neuron inspired threshold logic functions[6] implemented with memristors that have applications in high level pattern recognition applications. Some of the applications reported in recently include speech recognition,[28] face recognition[29] and object recognition.[30] They also find applications in replacing conventional digital logic gates.[31][32]

For ideal passive memristive circuits, it is possible to derive a differential equation for evolution of the internal memory of the circuit:[33]

d d t W → = α W → − 1 β ( I + ξ Ω W ) − 1 Ω S → {\displaystyle {\frac {d}{dt}}{\vec {W}}=\alpha {\vec {W}}-{\frac {1}{\beta }}(I+\xi \Omega W)^{-1}\Omega {\vec {S}}} {\displaystyle {\frac {d}{dt}}{\vec {W}}=\alpha {\vec {W}}-{\frac {1}{\beta }}(I+\xi \Omega W)^{-1}\Omega {\vec {S}}}

as a function of the properties of the physical memristive network and the external sources. In the equation above, α {\displaystyle \alpha } \alpha is the "forgetting" time scale constant, ξ = r − 1 {\displaystyle \xi =r-1} {\displaystyle \xi =r-1} and r = R o f f R o n {\displaystyle r={\frac {R_{off}}{R_{on}}}} {\displaystyle r={\frac {R_{off}}{R_{on}}}} is the ratio of off and on values of the limit resistances of the memristors, S → {\displaystyle {\vec {S}}} {\displaystyle {\vec {S}}} is the vector of the sources of the circuit and Ω {\displaystyle \Omega } \Omega is a projector on the fundamental loops of the circuit. The diagonal matrix and vector W = d i a g ( W → ) {\displaystyle W=diag({\vec {W}})} {\displaystyle W=diag({\vec {W}})} and W → {\displaystyle {\vec {W}}} {\displaystyle {\vec {W}}} respectively, are instead the internal value of the memristors, with values between 0 and 1. This equation thus requires to add extra constraints on the memory values in order to be reliable. 


